{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d83391a1-ec9b-4b5d-a81c-dd4c31e005e8",
   "metadata": {},
   "source": [
    "### Single Fold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "de26d22f-2255-43aa-81b8-1d20901c1076",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import deepdish\n",
    "import glob\n",
    "# import h5py11\n",
    "import lightning as L\n",
    "from lightning.pytorch.loggers import CSVLogger, TensorBoardLogger\n",
    "from lightning.pytorch.callbacks import ModelCheckpoint, EarlyStopping, TQDMProgressBar\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "import segmentation_models_pytorch as smp\n",
    "import torchvision.transforms as T\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.optim.lr_scheduler import CosineAnnealingLR, ReduceLROnPlateau\n",
    "from torch.optim import AdamW\n",
    "from torchmetrics.functional import dice\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import warnings\n",
    "import yaml\n",
    "# from pprint import pprint\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "5690d74a-3bb4-40bb-b5dc-fe0f001ec3cc",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class LightningModule(L.LightningModule):\n",
    "\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.model = smp.Unet(encoder_name = \"timm-resnest101e\",\n",
    "                              encoder_weights=None,\n",
    "                              in_channels=3,\n",
    "                              classes=1,\n",
    "                              activation=None,\n",
    "                              decoder_attention_type = \"scse\",\n",
    "                              )\n",
    "        self.loss_module = smp.losses.DiceLoss(mode=\"binary\", smooth=1)\n",
    "        self.val_step_outputs = []\n",
    "        self.val_step_labels = []\n",
    "\n",
    "    def forward(self, batch):\n",
    "        return self.model(batch)\n",
    "    \n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        imgs, labels = batch\n",
    "        preds = self.model(imgs)\n",
    "        preds = torch.nn.functional.interpolate(preds, size=256, mode='bilinear')\n",
    "        preds = torch.sigmoid(preds).cpu().detach().numpy()\n",
    "        predicted_mask_with_threshold = np.zeros((30,256, 256))\n",
    "        predicted_mask_with_threshold[preds[0, :, :] < 0.45] = 0\n",
    "        predicted_mask_with_threshold[preds[0, :, :] > 0.45] = 1\n",
    "        loss = self.loss_module(preds, labels)\n",
    "        self.log(\"val_loss\", loss, on_step=False, on_epoch=True, prog_bar=True)\n",
    "        self.val_step_outputs.append(preds)\n",
    "        self.val_step_labels.append(labels)\n",
    "\n",
    "    def on_validation_epoch_end(self):\n",
    "        all_preds = torch.cat(self.val_step_outputs)\n",
    "        all_labels = torch.cat(self.val_step_labels)\n",
    "        all_preds = torch.sigmoid(all_preds)\n",
    "        self.val_step_outputs.clear()\n",
    "        self.val_step_labels.clear()\n",
    "        val_dice = dice(all_preds, all_labels.long())\n",
    "        self.log(\"val_dice\", val_dice, on_step=False, on_epoch=True, prog_bar=True)\n",
    "        if self.trainer.global_rank == 0:\n",
    "            print(f\"\\nEpoch: {self.current_epoch}\", flush=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "5d9ee69f-7bc4-4b4c-b65d-0e8c617260cc",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "data_path_mf_train = \"/home/albert/ml/Contrails/data/full_dataset/train/\"\n",
    "data_path_mf_valid = \"/home/albert/ml/Contrails/data/full_dataset/validation/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "49eea235-cdf7-40ef-9d85-8f778e5b4190",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class ContrailsDatasetMixed(Dataset):\n",
    "    def __init__(self, split=\"train\", mode=\"single\", delta_t = 0):\n",
    "        self.delta_t = delta_t\n",
    "        self.split = split\n",
    "        self.mode = mode\n",
    "        self.path = (lambda x: data_path_mf_train if x == \"train\" else data_path_mf_valid)(self.split)\n",
    "        self.examples = os.listdir(self.path)\n",
    "        self.normalize_image = T.Normalize((0.485, 0.456, 0.406), (0.229, 0.224, 0.225))\n",
    "    \n",
    "    def read_record(self, directory):\n",
    "        record_data = {}\n",
    "        for x in [\n",
    "            \"band_11\", \n",
    "            \"band_14\", \n",
    "            \"band_15\"\n",
    "        ]:\n",
    "            record_data[x] = np.load(os.path.join(directory, x + \".npy\"))\n",
    "\n",
    "        return record_data\n",
    "\n",
    "    def normalize_range(self, data, bounds):\n",
    "        \"\"\"Maps data to the range [0, 1].\"\"\"\n",
    "        return (data - bounds[0]) / (bounds[1] - bounds[0])\n",
    "    \n",
    "    def get_false_color(self, record_data):\n",
    "        _T11_BOUNDS = (243, 303)\n",
    "        _CLOUD_TOP_TDIFF_BOUNDS = (-4, 5)\n",
    "        _TDIFF_BOUNDS = (-4, 2)\n",
    "        r = self.normalize_range(record_data[\"band_15\"] - record_data[\"band_14\"], _TDIFF_BOUNDS)\n",
    "        g = self.normalize_range(record_data[\"band_14\"] - record_data[\"band_11\"], _CLOUD_TOP_TDIFF_BOUNDS)\n",
    "        b = self.normalize_range(record_data[\"band_14\"], _T11_BOUNDS)\n",
    "        false_color = np.clip(np.stack([r, g, b], axis=2), 0, 1)\n",
    "        if self.mode == \"single\":\n",
    "            t_null = 4\n",
    "            return false_color[..., t_null+self.delta_t]\n",
    "        else:\n",
    "            return false_color\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        path = f\"{self.path}{self.examples[index]}\"\n",
    "        data = self.read_record(path)    \n",
    "        img = self.get_false_color(data)\n",
    "        if self.split == \"validation\":\n",
    "            label = np.load(os.path.join(path, \"human_pixel_masks.npy\")).squeeze()\n",
    "            label = torch.Tensor(label).to(torch.int64)\n",
    "        if self.split == \"train\":\n",
    "            label = np.load(os.path.join(path, \"human_pixel_masks.npy\")).squeeze()\n",
    "            label = torch.Tensor(label).to(torch.int64)\n",
    "            label_indiv = np.load(os.path.join(path, \"human_individual_masks.npy\")).squeeze()\n",
    "            labelers = label_indiv[1,1,:].shape[0]\n",
    "            label_union = torch.zeros([256, 256])\n",
    "            for i in range(labelers):\n",
    "                label_i = label_indiv[:, :,i]\n",
    "                label_union[label_i[:, :] == 1] = 1   \n",
    "\n",
    "        if self.mode == \"single\":\n",
    "            img = torch.tensor(np.reshape(img, (256, 256, 3, -1))).to(torch.float32).permute(3, 2, 0, 1).squeeze()\n",
    "        else:\n",
    "            img = torch.tensor(np.reshape(img, (256, 256, 3, -1))).to(torch.float32).permute(3, 2, 0, 1)\n",
    "\n",
    "        img = self.normalize_image(img)\n",
    "\n",
    "        if self.split in [\"train\"]:\n",
    "            return img.float(), [label.float(),label_union.float()]\n",
    "        if self.split in [\"validation\"]:\n",
    "            return img.float(), label.float()\n",
    "\n",
    "        return img.float()\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.examples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "4bd0b3b2-3eff-4128-b3b8-9b9f547d85ab",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "15631a34b34e4e789337b7108214f9e1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "IndexError",
     "evalue": "boolean index did not match indexed array along dimension 0; dimension is 30 but corresponding boolean dimension is 1",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[33], line 17\u001b[0m\n\u001b[1;32m     15\u001b[0m trainer \u001b[38;5;241m=\u001b[39m L\u001b[38;5;241m.\u001b[39mTrainer()\n\u001b[1;32m     16\u001b[0m model \u001b[38;5;241m=\u001b[39m LightningModule()\u001b[38;5;241m.\u001b[39mload_from_checkpoint(path)\n\u001b[0;32m---> 17\u001b[0m trainer\u001b[38;5;241m.\u001b[39mvalidate(model, data_loader_validation)\n",
      "File \u001b[0;32m~/miniconda3/envs/pytorch_gpu/lib/python3.11/site-packages/lightning/pytorch/trainer/trainer.py:628\u001b[0m, in \u001b[0;36mTrainer.validate\u001b[0;34m(self, model, dataloaders, ckpt_path, verbose, datamodule)\u001b[0m\n\u001b[1;32m    626\u001b[0m     model \u001b[38;5;241m=\u001b[39m _maybe_unwrap_optimized(model)\n\u001b[1;32m    627\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstrategy\u001b[38;5;241m.\u001b[39m_lightning_module \u001b[38;5;241m=\u001b[39m model\n\u001b[0;32m--> 628\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m call\u001b[38;5;241m.\u001b[39m_call_and_handle_interrupt(\n\u001b[1;32m    629\u001b[0m     \u001b[38;5;28mself\u001b[39m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_validate_impl, model, dataloaders, ckpt_path, verbose, datamodule\n\u001b[1;32m    630\u001b[0m )\n",
      "File \u001b[0;32m~/miniconda3/envs/pytorch_gpu/lib/python3.11/site-packages/lightning/pytorch/trainer/call.py:42\u001b[0m, in \u001b[0;36m_call_and_handle_interrupt\u001b[0;34m(trainer, trainer_fn, *args, **kwargs)\u001b[0m\n\u001b[1;32m     40\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m trainer\u001b[38;5;241m.\u001b[39mstrategy\u001b[38;5;241m.\u001b[39mlauncher \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m     41\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m trainer\u001b[38;5;241m.\u001b[39mstrategy\u001b[38;5;241m.\u001b[39mlauncher\u001b[38;5;241m.\u001b[39mlaunch(trainer_fn, \u001b[38;5;241m*\u001b[39margs, trainer\u001b[38;5;241m=\u001b[39mtrainer, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m---> 42\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m trainer_fn(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m     44\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m _TunerExitException:\n\u001b[1;32m     45\u001b[0m     _call_teardown_hook(trainer)\n",
      "File \u001b[0;32m~/miniconda3/envs/pytorch_gpu/lib/python3.11/site-packages/lightning/pytorch/trainer/trainer.py:671\u001b[0m, in \u001b[0;36mTrainer._validate_impl\u001b[0;34m(self, model, dataloaders, ckpt_path, verbose, datamodule)\u001b[0m\n\u001b[1;32m    666\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_data_connector\u001b[38;5;241m.\u001b[39mattach_data(model, val_dataloaders\u001b[38;5;241m=\u001b[39mdataloaders, datamodule\u001b[38;5;241m=\u001b[39mdatamodule)\n\u001b[1;32m    668\u001b[0m ckpt_path \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_checkpoint_connector\u001b[38;5;241m.\u001b[39m_select_ckpt_path(\n\u001b[1;32m    669\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate\u001b[38;5;241m.\u001b[39mfn, ckpt_path, model_provided\u001b[38;5;241m=\u001b[39mmodel_provided, model_connected\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlightning_module \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    670\u001b[0m )\n\u001b[0;32m--> 671\u001b[0m results \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_run(model, ckpt_path\u001b[38;5;241m=\u001b[39mckpt_path)\n\u001b[1;32m    672\u001b[0m \u001b[38;5;66;03m# remove the tensors from the validation results\u001b[39;00m\n\u001b[1;32m    673\u001b[0m results \u001b[38;5;241m=\u001b[39m convert_tensors_to_scalars(results)\n",
      "File \u001b[0;32m~/miniconda3/envs/pytorch_gpu/lib/python3.11/site-packages/lightning/pytorch/trainer/trainer.py:973\u001b[0m, in \u001b[0;36mTrainer._run\u001b[0;34m(self, model, ckpt_path)\u001b[0m\n\u001b[1;32m    968\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_signal_connector\u001b[38;5;241m.\u001b[39mregister_signal_handlers()\n\u001b[1;32m    970\u001b[0m \u001b[38;5;66;03m# ----------------------------\u001b[39;00m\n\u001b[1;32m    971\u001b[0m \u001b[38;5;66;03m# RUN THE TRAINER\u001b[39;00m\n\u001b[1;32m    972\u001b[0m \u001b[38;5;66;03m# ----------------------------\u001b[39;00m\n\u001b[0;32m--> 973\u001b[0m results \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_run_stage()\n\u001b[1;32m    975\u001b[0m \u001b[38;5;66;03m# ----------------------------\u001b[39;00m\n\u001b[1;32m    976\u001b[0m \u001b[38;5;66;03m# POST-Training CLEAN UP\u001b[39;00m\n\u001b[1;32m    977\u001b[0m \u001b[38;5;66;03m# ----------------------------\u001b[39;00m\n\u001b[1;32m    978\u001b[0m log\u001b[38;5;241m.\u001b[39mdebug(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m: trainer tearing down\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/miniconda3/envs/pytorch_gpu/lib/python3.11/site-packages/lightning/pytorch/trainer/trainer.py:1009\u001b[0m, in \u001b[0;36mTrainer._run_stage\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1006\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstrategy\u001b[38;5;241m.\u001b[39mbarrier(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrun-stage\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m   1008\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mevaluating:\n\u001b[0;32m-> 1009\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_evaluation_loop\u001b[38;5;241m.\u001b[39mrun()\n\u001b[1;32m   1010\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpredicting:\n\u001b[1;32m   1011\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpredict_loop\u001b[38;5;241m.\u001b[39mrun()\n",
      "File \u001b[0;32m~/miniconda3/envs/pytorch_gpu/lib/python3.11/site-packages/lightning/pytorch/loops/utilities.py:177\u001b[0m, in \u001b[0;36m_no_grad_context.<locals>._decorator\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    175\u001b[0m     context_manager \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mno_grad\n\u001b[1;32m    176\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m context_manager():\n\u001b[0;32m--> 177\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m loop_run(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m~/miniconda3/envs/pytorch_gpu/lib/python3.11/site-packages/lightning/pytorch/loops/evaluation_loop.py:115\u001b[0m, in \u001b[0;36m_EvaluationLoop.run\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    113\u001b[0m     previous_dataloader_idx \u001b[38;5;241m=\u001b[39m dataloader_idx\n\u001b[1;32m    114\u001b[0m     \u001b[38;5;66;03m# run step hooks\u001b[39;00m\n\u001b[0;32m--> 115\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_evaluation_step(batch, batch_idx, dataloader_idx)\n\u001b[1;32m    116\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mStopIteration\u001b[39;00m:\n\u001b[1;32m    117\u001b[0m     \u001b[38;5;66;03m# this needs to wrap the `*_step` call too (not just `next`) for `dataloader_iter` support\u001b[39;00m\n\u001b[1;32m    118\u001b[0m     \u001b[38;5;28;01mbreak\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/pytorch_gpu/lib/python3.11/site-packages/lightning/pytorch/loops/evaluation_loop.py:375\u001b[0m, in \u001b[0;36m_EvaluationLoop._evaluation_step\u001b[0;34m(self, batch, batch_idx, dataloader_idx)\u001b[0m\n\u001b[1;32m    372\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbatch_progress\u001b[38;5;241m.\u001b[39mincrement_started()\n\u001b[1;32m    374\u001b[0m hook_name \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtest_step\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m trainer\u001b[38;5;241m.\u001b[39mtesting \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mvalidation_step\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m--> 375\u001b[0m output \u001b[38;5;241m=\u001b[39m call\u001b[38;5;241m.\u001b[39m_call_strategy_hook(trainer, hook_name, \u001b[38;5;241m*\u001b[39mstep_kwargs\u001b[38;5;241m.\u001b[39mvalues())\n\u001b[1;32m    377\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbatch_progress\u001b[38;5;241m.\u001b[39mincrement_processed()\n\u001b[1;32m    379\u001b[0m hook_name \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mon_test_batch_end\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m trainer\u001b[38;5;241m.\u001b[39mtesting \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mon_validation_batch_end\u001b[39m\u001b[38;5;124m\"\u001b[39m\n",
      "File \u001b[0;32m~/miniconda3/envs/pytorch_gpu/lib/python3.11/site-packages/lightning/pytorch/trainer/call.py:291\u001b[0m, in \u001b[0;36m_call_strategy_hook\u001b[0;34m(trainer, hook_name, *args, **kwargs)\u001b[0m\n\u001b[1;32m    288\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    290\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m trainer\u001b[38;5;241m.\u001b[39mprofiler\u001b[38;5;241m.\u001b[39mprofile(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m[Strategy]\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtrainer\u001b[38;5;241m.\u001b[39mstrategy\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mhook_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m):\n\u001b[0;32m--> 291\u001b[0m     output \u001b[38;5;241m=\u001b[39m fn(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    293\u001b[0m \u001b[38;5;66;03m# restore current_fx when nested context\u001b[39;00m\n\u001b[1;32m    294\u001b[0m pl_module\u001b[38;5;241m.\u001b[39m_current_fx_name \u001b[38;5;241m=\u001b[39m prev_fx_name\n",
      "File \u001b[0;32m~/miniconda3/envs/pytorch_gpu/lib/python3.11/site-packages/lightning/pytorch/strategies/strategy.py:379\u001b[0m, in \u001b[0;36mStrategy.validation_step\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    377\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprecision_plugin\u001b[38;5;241m.\u001b[39mval_step_context():\n\u001b[1;32m    378\u001b[0m     \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel, ValidationStep)\n\u001b[0;32m--> 379\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel\u001b[38;5;241m.\u001b[39mvalidation_step(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "Cell \u001b[0;32mIn[30], line 25\u001b[0m, in \u001b[0;36mLightningModule.validation_step\u001b[0;34m(self, batch, batch_idx)\u001b[0m\n\u001b[1;32m     23\u001b[0m preds \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39msigmoid(preds)\u001b[38;5;241m.\u001b[39mcpu()\u001b[38;5;241m.\u001b[39mdetach()\u001b[38;5;241m.\u001b[39mnumpy()\n\u001b[1;32m     24\u001b[0m predicted_mask_with_threshold \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mzeros((\u001b[38;5;241m30\u001b[39m,\u001b[38;5;241m256\u001b[39m, \u001b[38;5;241m256\u001b[39m))\n\u001b[0;32m---> 25\u001b[0m predicted_mask_with_threshold[preds[\u001b[38;5;241m0\u001b[39m, :, :] \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m0.45\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[1;32m     26\u001b[0m predicted_mask_with_threshold[preds[\u001b[38;5;241m0\u001b[39m, :, :] \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0.45\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m     27\u001b[0m loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mloss_module(preds, labels)\n",
      "\u001b[0;31mIndexError\u001b[0m: boolean index did not match indexed array along dimension 0; dimension is 30 but corresponding boolean dimension is 1"
     ]
    }
   ],
   "source": [
    "path = '/home/albert/ml/Contrails/notebooks/full_dataset/test_use_all_bands/resnest101e_ash_attention_sample_loss_kfold/model-f3-val_dice=0.6537.ckpt'\n",
    "\n",
    "dataset_validation = ContrailsDatasetMixed(\"validation\",\"single\", 0)\n",
    "data_loader_validation = DataLoader(\n",
    "    dataset_validation,\n",
    "    batch_size=30,\n",
    "    shuffle=False,\n",
    "    num_workers=1,\n",
    ")\n",
    "\n",
    "progress_bar_callback = TQDMProgressBar(\n",
    "refresh_rate=1\n",
    ")\n",
    "\n",
    "trainer = L.Trainer()\n",
    "model = LightningModule().load_from_checkpoint(path)\n",
    "trainer.validate(model, data_loader_validation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cb3a97d-ba6c-445f-be1d-4dfb4ca58b5e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.11.3 (pytorch_gpu)",
   "language": "python",
   "name": "pytorch_gpu"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
